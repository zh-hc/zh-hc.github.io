<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>CUDA编程实现求解单源Bellman-Ford最短路径算法 | baymin</title>
<link rel="shortcut icon" href="https://blog.baymin.eu.org/favicon.ico?v=1658276127496">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://blog.baymin.eu.org/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="CUDA编程实现求解单源Bellman-Ford最短路径算法 | baymin - Atom Feed" href="https://blog.baymin.eu.org/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="CUDA介绍
什么类型的程序适合在GPU上运行？

计算密集型的程序。
易于并行的程序。GPU其实是一种SIMD(Single Instruction Multiple Data)架构。

CUDA是什么？

CUDA，全称是Compute..." />
    <meta name="keywords" content="高性能计算" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://blog.baymin.eu.org">
  <img class="avatar" src="https://blog.baymin.eu.org/images/avatar.png?v=1658276127496" alt="">
  </a>
  <h1 class="site-title">
    baymin
  </h1>
  <p class="site-description">
    一蓑烟雨任平生
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
      
        <a href="/post/link" class="menu">
          书签
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              CUDA编程实现求解单源Bellman-Ford最短路径算法
            </h2>
            <div class="post-info">
              <span>
                2022-06-19
              </span>
              <span>
                11 min read
              </span>
              
                <a href="https://blog.baymin.eu.org/tag/zfZDB3FbB/" class="post-tag">
                  # 高性能计算
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <h2 id="cuda介绍">CUDA介绍</h2>
<p><strong>什么类型的程序适合在GPU上运行？</strong></p>
<ol>
<li>计算密集型的程序。</li>
<li>易于并行的程序。GPU其实是一种SIMD(Single Instruction Multiple Data)架构。</li>
</ol>
<p><strong>CUDA是什么？</strong></p>
<ul>
<li>CUDA，全称是Compute Unified Device Architecture，英伟达在2007年推出这个统一计算架构，为了让GPU有可用的编程环境，从而能通过程序控制底层的硬件进行计算。</li>
<li>CUDA提供host-device的编程模式以及非常多的接口函数和科学计算库，通过同时执行大量的线程而达到并行的目的。CUDA也有不同的版本，从1.0开始到现在的8.0，每个版本都会有一些新特性。CUDA是基于C语言的扩展，例如扩展了一些限定符device、shared等，从3.0开始也支持C++编程，从7.0开始支持C++11。</li>
</ul>
<h2 id="算法流程">算法流程</h2>
<ol>
<li>初始化
<ul>
<li>通过读文件的形式将数据读入到一维数组中</li>
</ul>
</li>
<li><strong>松弛</strong>（重点部分）
<ul>
<li>该部分是本算法中计算量最大的部分，也是使用GPU进行计算的部分</li>
<li>通过给一维数组中的顶点分配线程并行进行松弛操作，来有效降低运行时间</li>
</ul>
</li>
<li>检验是否有负权环</li>
<li>结果输出
<ul>
<li>将结果输出到<code>output.txt</code>中，若不存在负权环，则输出最小距离；若存在负权环，则输出<code>FOUND NEGATIVE CYCLE!</code></li>
</ul>
</li>
</ol>
<h2 id="算法代码">算法代码</h2>
<p><strong>输入格式</strong></p>
<ul>
<li>第一行是一个整数<code>N</code>，表示输入图中的顶点数；</li>
<li>下面的N行是一个<code>N*N</code>邻接矩阵；</li>
<li>记行为<code>v</code>，列为<code>w</code>，那么<code>mat[v][w]</code>是指从顶点<code>v</code>到顶点<code>w</code>的距离(权重)；</li>
<li>所有的距离都是整数；</li>
<li>如果没有边连接顶点<code>v</code>和<code>w</code>，那么<code>mat[v][w]</code>将使用1000000(<code>INF</code>)来表示无穷大；</li>
<li>顶点的序号是非负连续的整数，对于一个有<code>N</code>个顶点的输入图，顶点将被标记为0,1,2，... ，N-1；</li>
<li>我们总是使用顶点0作为源顶点。</li>
</ul>
<p><strong>输出格式</strong></p>
<ul>
<li>输出文件包含从<code>顶点0</code>到所有顶点的距离，按照顶点序号(0,1,2，... )的递增顺序，每行一个距离；</li>
<li>如果至少有一个负循环(图中循环的权重之和为负) ，程序将变量 <code>has_NEGATIVE_CYCLE</code> 设置为 true 并打印&quot;FOUND NEGATIVE CYCLE!&quot;(发现负权环)，因为此时没有最短路径。</li>
</ul>
<p><strong>核函数结构</strong></p>
<pre><code class="language-C++">// GPU执行 CPU调用
bellman_ford_one_iter&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(n, d_mat, d_dist, d_has_next, iter_num);

// 核函数
// __global__ GPU执行部分 核函数
// n：顶点数量
// d_mat：矩阵
// d_dist：距离
// blockDim.x是线程块在x方向上的线程数（在x方向上每一个线程块有多少个线程）
// blockIdx.x是线程块在x方向上的索引
// threadIdx.x是线程在X方向上的索引（在自己的线程块内）
// gridDim.x表示x方向有几个block
__global__ void bellman_ford_one_iter(int n, int *d_mat, int *d_dist, bool *d_has_next, int iter_num) {
    int global_tid = blockDim.x * blockIdx.x + threadIdx.x; // 计算线程号global_tid 一维只需要在x方向上做计算
    int elementSkip = blockDim.x * gridDim.x;

    if(global_tid &gt;= n) return;
    for(int u = 0 ; u &lt; n ; u ++) {
        for(int v = global_tid; v &lt; n; v+= elementSkip) {
            int weight = d_mat[u * n + v];
            if(weight &lt; INF) {
                // 松弛操作
                int new_dist = d_dist[u] + weight;
                if(new_dist &lt; d_dist[v]) {
                    d_dist[v] = new_dist;
                    *d_has_next = true;
                }
            }
        }
    }
}
</code></pre>
<p><strong>核函数线程分配</strong><br>
<img src="https://blog.baymin.eu.org/post-images/1655693822273.jpg" alt="" loading="lazy"></p>
<p><strong>优化策略</strong><br>
通过利用GPU进行并行编程，提高了算法效率，尤其在数据集较大的情况下更为明显。</p>
<p><strong>源代码</strong></p>
<pre><code class="language-C++">// 这是CUDA版本的单源Bellman-Ford最短路径算法

// 编译
// nvcc cuda.cu -o cuda
// 运行
// ./cuda input1.txt &lt;每个网格的线程块的数量&gt; &lt;每个线程块的线程数量&gt;

// 可以在output.txt中看到结果记录

#include &lt;string&gt;
#include &lt;cassert&gt;
#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;algorithm&gt;
#include &lt;iomanip&gt;
#include &lt;cstring&gt;
#include &lt;sys/time.h&gt;
#include &lt;cuda_runtime.h&gt;
#include &lt;device_launch_parameters.h&gt;

// using namespace std 的进化版本
using std::string;
using std::cout;
using std::endl;

// 无穷大
#define INF 1000000

/*
 * This is a CHECK function to check CUDA calls
 */
#define CHECK(call) {                                                                \
    const cudaError_t error = call;                                                  \
    if (error != cudaSuccess) {                                                      \
        fprintf(stderr, &quot;Error: %s:%d, &quot;, __FILE__, __LINE__);                       \
        fprintf(stderr, &quot;code: %d, reason: %s\n&quot;, error, cudaGetErrorString(error)); \
        exit(1);                                                                     \
    }                                                                                \
}

// utils是实用程序功能的命名空间
// 包括I/O（读取输入文件和打印结果）和矩阵维度转换（2D-&gt;1D）函数
namespace utils {
    int N;    // 顶点数量
    int *mat; // the adjacency matrix 邻接矩阵

    void abort_with_error_message(string msg) {
        std::cerr &lt;&lt; msg &lt;&lt; endl;
        abort();
    }

    // 将二维转换为一维
    int convert_dimension_2D_1D(int x, int y, int n) {
        return x * n + y;
    }

    // 读取文件 获取整个矩阵 并经过转换存储在一维数组中
    int read_file(string filename) {
        std::ifstream inputf(filename, std::ifstream::in);
        if (!inputf.good()) {
            abort_with_error_message(&quot;ERROR OCCURRED WHILE READING INPUT FILE&quot;);
        }
        inputf &gt;&gt; N;
        // 对输入的矩阵做一个 20MB * 20MB 的限制 (400MB)
        assert(N &lt; (1024 * 1024 * 20));
        mat = (int *) malloc(N * N * sizeof(int));
        for (int i = 0; i &lt; N; i++)
            for (int j = 0; j &lt; N; j++) {
                // 通过convert_dimension_2D_1D函数将二维数据转换成一维存放到mat数组中
                inputf &gt;&gt; mat[convert_dimension_2D_1D(i, j, N)];
            }
        return 0;
    }

    // 结果输出到output.txt中
    int print_result(bool has_negative_cycle, int *dist) {
        std::ofstream outputf(&quot;output.txt&quot;, std::ofstream::out);
        if (!has_negative_cycle) { // 不含有负权环则输出正确结果到文件中
            for (int i = 0; i &lt; N; i++) {
                if (dist[i] &gt; INF)
                    dist[i] = INF;
                outputf &lt;&lt; dist[i] &lt;&lt; '\n';
            }
            outputf.flush();
        } else { // 含有负权环 输出FOUND NEGATIVE CYCLE!
            outputf &lt;&lt; &quot;FOUND NEGATIVE CYCLE!&quot; &lt;&lt; endl;
        }
        outputf.close();
        return 0;
    }
} // utils命名空间

// __global__ GPU执行部分 核函数
// n：顶点数量
// d_mat：矩阵
// d_dist：距离
// blockDim.x是线程块在x方向上的线程数（在x方向上每一个线程块有多少个线程）
// blockIdx.x是线程块在x方向上的索引
// threadIdx.x是线程在X方向上的索引（在自己的线程块内）
// gridDim.x表示x方向有几个block
__global__ void bellman_ford_one_iter(int n, int *d_mat, int *d_dist, bool *d_has_next, int iter_num) {
    int global_tid = blockDim.x * blockIdx.x + threadIdx.x; // 计算线程号global_tid 一维只需要在x方向上做计算
    int elementSkip = blockDim.x * gridDim.x;

    if(global_tid &gt;= n) return;
    for(int u = 0 ; u &lt; n ; u ++) {
        for(int v = global_tid; v &lt; n; v+= elementSkip) {
            int weight = d_mat[u * n + v];
            if(weight &lt; INF) {
                // 松弛操作
                int new_dist = d_dist[u] + weight;
                if(new_dist &lt; d_dist[v]) {
                    d_dist[v] = new_dist;
                    *d_has_next = true;
                }
            }
        }
    }
}

// Bellman-Ford算法。找到从顶点0到其他顶点的最短路径。
/**
 * @param blockPerGrid 每个网格中线程块的个数
 * @param threadsPerBlock 每个线程块中线程的个数
 * @param n input size
 * @param *mat input adjacency matrix
 * @param *dist 距离数组
 * @param *has_negative_cycle 一个记录是否含有负权环的变量
 */
void bellman_ford(int blocksPerGrid, int threadsPerBlock, int n, int *mat, int *dist, bool *has_negative_cycle) {
    dim3 blocks(blocksPerGrid);
    dim3 threads(threadsPerBlock);

    // 计数 记录循环次数
    int iter_num = 0;

    int *d_mat, *d_dist;
    bool *d_has_next, h_has_next;

    // GPU全局内存分配
    // cudaError_t cudaMalloc(void **devPtr, size_t size);
    cudaMalloc(&amp;d_mat, sizeof(int) * n * n);
    cudaMalloc(&amp;d_dist, sizeof(int) *n);
    cudaMalloc(&amp;d_has_next, sizeof(bool));

    // 是否有负权环的标志位
    *has_negative_cycle = false;

    // 初始化 将所有距离置为无穷大
    for(int i = 0 ; i &lt; n; i ++) {
        dist[i] = INF;
    }

    // 到自己的距离置为0
    dist[0] = 0;

    // CPU与GPU内存同步拷贝
    // cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind)
    // kind: cudaMemcpyHostToHost, cudaMemcpyHostToDevice, cudaMemcpyDeviceToHost, cudaMemcpyDeviceToDevice, or cudaMemcpyDefault
    cudaMemcpy(d_mat, mat, sizeof(int) * n * n, cudaMemcpyHostToDevice);
    cudaMemcpy(d_dist, dist, sizeof(int) * n, cudaMemcpyHostToDevice);

    for(;;) {
        h_has_next = false;
        cudaMemcpy(d_has_next, &amp;h_has_next, sizeof(bool), cudaMemcpyHostToDevice);

        // 松弛操作 由GPU进行
        bellman_ford_one_iter&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(n, d_mat, d_dist, d_has_next, iter_num);

        CHECK(cudaDeviceSynchronize());
        cudaMemcpy(&amp;h_has_next, d_has_next, sizeof(bool), cudaMemcpyDeviceToHost);

        iter_num++; // 循环次数加一

        if(iter_num &gt;= n-1) { // 如果循环次数大于n-1 说明存在负权环
            *has_negative_cycle = true;
            break;
        }

        if(!h_has_next) {
            break;
        }
    }

    if(! *has_negative_cycle) {
        cudaMemcpy(dist, d_dist, sizeof(int) * n, cudaMemcpyDeviceToHost);
    }

    // GPU全局内存释放
    // cudaError_t cudaFree(void *devPtr);
    cudaFree(d_mat);
    cudaFree(d_dist);
    cudaFree(d_has_next);
}

int main(int argc, char **argv) {
    if (argc &lt;= 1) { // 没有写输入文件的情况
        utils::abort_with_error_message(&quot;INPUT FILE WAS NOT FOUND!&quot;);
    }
    if (argc &lt;= 3) { // 没有写块数量或者进程数的情况
        utils::abort_with_error_message(&quot;blocksPerGrid or threadsPerBlock WAS NOT FOUND!&quot;);
    }

    // 保存输入文件名
    string filename = argv[1];
    // 每个网格中线程块的个数
    int blockPerGrid = atoi(argv[2]);
    // 每个线程块中线程的个数
    int threadsPerBlock = atoi(argv[3]);

    int *dist;
    bool has_negative_cycle = false;

    assert(utils::read_file(filename) == 0);
    dist = (int *) calloc(sizeof(int), utils::N);

    // 计时器
    timeval start_wall_time_t, end_wall_time_t;
    float ms_wall;
    cudaDeviceReset();

    // 开始计时
    gettimeofday(&amp;start_wall_time_t, nullptr);

    //bellman-ford算法
    bellman_ford(blockPerGrid, threadsPerBlock, utils::N, utils::mat, dist, &amp;has_negative_cycle);
    CHECK(cudaDeviceSynchronize());

    // 结束计时
    gettimeofday(&amp;end_wall_time_t, nullptr);

    ms_wall = ((end_wall_time_t.tv_sec - start_wall_time_t.tv_sec) * 1000 * 1000
            + end_wall_time_t.tv_usec - start_wall_time_t.tv_usec) / 1000.0;

    std::cerr.setf(std::ios::fixed);
    std::cerr &lt;&lt; std::setprecision(6) &lt;&lt; &quot;Time(s): &quot; &lt;&lt; (ms_wall/1000.0) &lt;&lt; endl;
    utils::print_result(has_negative_cycle, dist);
    free(dist);
    free(utils::mat);

    return 0;
}
</code></pre>
<h2 id="测试结果">测试结果</h2>
<figure data-type="image" tabindex="1"><img src="https://blog.baymin.eu.org/post-images/1655627951428.png" alt="" loading="lazy"></figure>
<h2 id="测试结果分析">测试结果分析</h2>
<ol>
<li>在数据集方面，我们有一个<code>4*4</code>的矩阵输入和一个<code>1500*1500</code>的矩阵输入作为对照，分别测试运行时间以及提速效果，显然数据集越大，CUDA的效果越明显；</li>
<li>通过对<code>4*4</code>矩阵输入的结果输出<code>output.txt</code>文件进行分析，确定计算结果无误；</li>
<li>在代码运行方面，以<code>1500*1500</code>的矩阵作为固定输入，显然，随着<code>blockPerGrid</code>和<code>threadsPerBlock</code>的增加，运行时间越来越短，这是实验中我们最期望看到的理想状况。</li>
</ol>
<h2 id="不足和改进之处">不足和改进之处</h2>
<ol>
<li>由于本次实验数据集我们只找到了<code>1500*1500</code>的，数据规模虽然可以体现出改进的效果，但是还有更大的进步空间；</li>
<li>为了方便起见，我们使用的是一维进行操作，可以经过进一步改进，改成高维计算。</li>
</ol>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#cuda%E4%BB%8B%E7%BB%8D">CUDA介绍</a></li>
<li><a href="#%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B">算法流程</a></li>
<li><a href="#%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81">算法代码</a></li>
<li><a href="#%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C">测试结果</a></li>
<li><a href="#%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">测试结果分析</a></li>
<li><a href="#%E4%B8%8D%E8%B6%B3%E5%92%8C%E6%94%B9%E8%BF%9B%E4%B9%8B%E5%A4%84">不足和改进之处</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://blog.baymin.eu.org/post/qian-tan-dan-yuan-zui-duan-lu-jing-suan-fa/">
              <h3 class="post-title">
                浅谈单源Bellman-Ford最短路径算法
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  <a href="https://time.is/Beijing" id="time_is_link" rel="nofollow" style="font-size:12px">北京时间:</a>
<span id="Beijing_z43d" style="font-size:12px"></span>
<script src="//widget.time.is/zh.js"></script>
<script>
time_is_widget.init({Beijing_z43d:{template:"TIME<br>DATE<br>SUN", date_format:"year-monthnum-daynumdayname", sun_format:"日出: srhour:srminute 日落: sshour:ssminute<br>昼长: dlhours时 dlminutes分", coords:"39.9075000,116.3972300"}});
</script>
  <a class="rss" href="https://blog.baymin.eu.org/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
